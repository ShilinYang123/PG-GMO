#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬äºŒé˜¶æ®µï¼šæµç¨‹å›¾é€‚ç”¨æ€§ç­›é€‰å·¥å…·
æ ¹æ®ä»»åŠ¡ä¹¦ç­›é€‰æ ‡å‡†ï¼Œè¯†åˆ«é€‚åˆç”Ÿæˆæµç¨‹å›¾çš„æ–‡æ¡£ç±»å‹
"""

import json
import os
from pathlib import Path

def load_analysis_results():
    """åŠ è½½ç¬¬ä¸€é˜¶æ®µçš„åˆ†æç»“æœ"""
    results_file = Path("S:/PG-GMO/02-Output/ISOæ–‡æ¡£åˆ†æç»“æœ.json")
    if not results_file.exists():
        print(f"âŒ åˆ†æç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {results_file}")
        return []
    
    with open(results_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def apply_task_book_criteria(documents):
    """æ ¹æ®ä»»åŠ¡ä¹¦æ ‡å‡†è¿›è¡Œç²¾ç¡®ç­›é€‰"""
    
    # ä»»åŠ¡ä¹¦æ˜ç¡®è¦æ±‚çš„é€‚åˆç±»å‹
    suitable_types = {
        'å·¥ä½œæµç¨‹ç±»': ['å·¥ä½œæµç¨‹', 'ä½œä¸šæµç¨‹', 'æ“ä½œæµç¨‹', 'ä¸šåŠ¡æµç¨‹'],
        'æ“ä½œç¨‹åºç±»': ['æ“ä½œç¨‹åº', 'ä½œä¸šç¨‹åº', 'å·¥è‰ºç¨‹åº', 'ç”Ÿäº§ç¨‹åº'],
        'å®¡æ‰¹æµç¨‹ç±»': ['å®¡æ‰¹æµç¨‹', 'è¯„å®¡ç¨‹åº', 'å®¡æ ¸ç¨‹åº', 'æ‰¹å‡†ç¨‹åº'],
        'è´¨é‡æ§åˆ¶ç±»': ['è´¨é‡æ§åˆ¶', 'å“è´¨æ§åˆ¶', 'æ£€éªŒç¨‹åº', 'æµ‹è¯•ç¨‹åº'],
        'æ£€éªŒç¨‹åºç±»': ['æ£€éªŒç¨‹åº', 'æ£€æµ‹ç¨‹åº', 'è¯•éªŒç¨‹åº', 'éªŒè¯ç¨‹åº'],
        'ç®¡ç†æµç¨‹ç±»': ['ç®¡ç†ç¨‹åº', 'æ§åˆ¶ç¨‹åº', 'ç®¡ç†æµç¨‹', 'æ§åˆ¶æµç¨‹']
    }
    
    # éœ€è¦æ’é™¤çš„ç±»å‹
    exclude_types = {
        'çº¯è¡¨å•ç±»': ['è¡¨å•', 'è®°å½•è¡¨', 'ç™»è®°è¡¨', 'ç»Ÿè®¡è¡¨', 'æ¸…å•'],
        'çº¯åˆ¶åº¦ç±»': ['åˆ¶åº¦', 'è§„å®š', 'åŠæ³•', 'æ¡ä¾‹', 'å‡†åˆ™', 'æ ‡å‡†']
    }
    
    filtered_results = []
    category_stats = {}
    
    for doc in documents:
        filename = doc['filename']
        original_category = doc['analysis']['category']
        
        # é‡æ–°åˆ†ç±»å’Œç­›é€‰
        new_category = None
        is_suitable = False
        exclusion_reason = None
        
        # æ£€æŸ¥æ˜¯å¦å±äºæ’é™¤ç±»å‹
        for exclude_cat, keywords in exclude_types.items():
            if any(keyword in filename for keyword in keywords):
                exclusion_reason = f"å±äº{exclude_cat}ï¼Œä¸é€‚åˆç”Ÿæˆæµç¨‹å›¾"
                break
        
        if not exclusion_reason:
            # æ£€æŸ¥æ˜¯å¦å±äºé€‚åˆç±»å‹
            for suit_cat, keywords in suitable_types.items():
                if any(keyword in filename for keyword in keywords):
                    new_category = suit_cat
                    is_suitable = True
                    break
        
        # æ›´æ–°æ–‡æ¡£ä¿¡æ¯
        doc['analysis']['task_book_suitable'] = is_suitable
        doc['analysis']['task_book_category'] = new_category
        doc['analysis']['exclusion_reason'] = exclusion_reason
        
        if is_suitable:
            filtered_results.append(doc)
            category_stats[new_category] = category_stats.get(new_category, 0) + 1
    
    return filtered_results, category_stats

def generate_filter_report(original_docs, filtered_docs, category_stats):
    """ç”Ÿæˆç­›é€‰æŠ¥å‘Š"""
    report = []
    report.append("# ç¬¬äºŒé˜¶æ®µï¼šæµç¨‹å›¾é€‚ç”¨æ€§ç­›é€‰æŠ¥å‘Š")
    report.append("")
    report.append(f"## ç­›é€‰ç»“æœç»Ÿè®¡")
    report.append(f"- åŸå§‹æ–‡æ¡£æ•°é‡: {len(original_docs)}")
    report.append(f"- ç­›é€‰åé€‚åˆæ–‡æ¡£æ•°é‡: {len(filtered_docs)}")
    report.append(f"- ç­›é€‰ç‡: {len(filtered_docs)/len(original_docs)*100:.1f}%")
    report.append("")
    
    report.append("## æŒ‰ç±»å‹åˆ†å¸ƒ")
    for category, count in category_stats.items():
        report.append(f"- {category}: {count}ä¸ª")
    report.append("")
    
    report.append("## é€‚åˆç”Ÿæˆæµç¨‹å›¾çš„æ–‡æ¡£æ¸…å•")
    for i, doc in enumerate(filtered_docs, 1):
        category = doc['analysis']['task_book_category']
        confidence = doc['analysis']['confidence']
        report.append(f"{i}. **{doc['filename']}**")
        report.append(f"   - åˆ†ç±»: {category}")
        report.append(f"   - ç½®ä¿¡åº¦: {confidence}%")
        report.append("")
    
    # æ˜¾ç¤ºè¢«æ’é™¤çš„æ–‡æ¡£
    excluded_docs = [doc for doc in original_docs if not doc['analysis']['task_book_suitable']]
    if excluded_docs:
        report.append("## è¢«æ’é™¤çš„æ–‡æ¡£")
        for doc in excluded_docs:
            reason = doc['analysis']['exclusion_reason']
            report.append(f"- **{doc['filename']}**: {reason}")
        report.append("")
    
    return "\n".join(report)

def main():
    print("=== ç¬¬äºŒé˜¶æ®µï¼šæµç¨‹å›¾é€‚ç”¨æ€§ç­›é€‰ ===")
    
    # åŠ è½½ç¬¬ä¸€é˜¶æ®µç»“æœ
    documents = load_analysis_results()
    if not documents:
        return
    
    print(f"ğŸ“„ åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£çš„åˆ†æç»“æœ")
    
    # åº”ç”¨ä»»åŠ¡ä¹¦ç­›é€‰æ ‡å‡†
    filtered_docs, category_stats = apply_task_book_criteria(documents)
    
    print(f"\n=== ç­›é€‰ç»“æœ ===")
    print(f"åŸå§‹æ–‡æ¡£: {len(documents)} ä¸ª")
    print(f"é€‚åˆç”Ÿæˆæµç¨‹å›¾: {len(filtered_docs)} ä¸ª")
    print(f"ç­›é€‰ç‡: {len(filtered_docs)/len(documents)*100:.1f}%")
    
    print(f"\n=== åˆ†ç±»ç»Ÿè®¡ ===")
    for category, count in category_stats.items():
        print(f"{category}: {count} ä¸ª")
    
    # ç”ŸæˆæŠ¥å‘Š
    report_content = generate_filter_report(documents, filtered_docs, category_stats)
    
    # ä¿å­˜ç­›é€‰ç»“æœ
    output_dir = Path("S:/PG-GMO/02-Output")
    output_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜ç­›é€‰åçš„JSONæ•°æ®
    filtered_json_file = output_dir / "æµç¨‹å›¾é€‚ç”¨æ–‡æ¡£ç­›é€‰ç»“æœ.json"
    with open(filtered_json_file, 'w', encoding='utf-8') as f:
        json.dump(filtered_docs, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜ç­›é€‰æŠ¥å‘Š
    report_file = output_dir / "ç¬¬äºŒé˜¶æ®µç­›é€‰æŠ¥å‘Š.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"\nğŸ“„ ç­›é€‰ç»“æœå·²ä¿å­˜: {filtered_json_file}")
    print(f"ğŸ“„ ç­›é€‰æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    print(f"\n=== ç¬¬äºŒé˜¶æ®µï¼šæµç¨‹å›¾é€‚ç”¨æ€§ç­›é€‰ å®Œæˆ ===")
    print(f"å…±ç­›é€‰å‡º {len(filtered_docs)} ä¸ªé€‚åˆç”Ÿæˆæµç¨‹å›¾çš„æ–‡æ¡£")
    
    return filtered_docs

if __name__ == "__main__":
    main()