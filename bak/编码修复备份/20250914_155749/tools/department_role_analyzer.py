#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å“é«˜ISOæ–‡æ¡£éƒ¨é—¨è§’è‰²ç»Ÿè®¡åˆ†æå™¨
ç»Ÿè®¡æ‰€æœ‰ISOæ–‡æ¡£ä¸­å‡ºç°çš„éƒ¨é—¨å’Œè§’è‰²åç§°
"""

import os
import re
import json
from pathlib import Path
from collections import Counter, defaultdict
from datetime import datetime
import subprocess
import sys

class DepartmentRoleAnalyzer:
    def __init__(self, input_dir, output_dir):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # éƒ¨é—¨å…³é”®è¯æ¨¡å¼
        self.department_patterns = [
            r'(\w*éƒ¨)(?![é—¨æˆ·])',  # ä»¥"éƒ¨"ç»“å°¾çš„è¯
            r'(\w*å®¤)(?![å†…å¤–])',  # ä»¥"å®¤"ç»“å°¾çš„è¯
            r'(\w*ç§‘)(?![å­¦æŠ€])',  # ä»¥"ç§‘"ç»“å°¾çš„è¯
            r'(\w*ç»„)(?![ç»‡æˆ])',  # ä»¥"ç»„"ç»“å°¾çš„è¯
            r'(\w*ä¸­å¿ƒ)',         # ä»¥"ä¸­å¿ƒ"ç»“å°¾çš„è¯
            r'(\w*åŠå…¬å®¤)',       # åŠå…¬å®¤
            r'(æ€»ç»åŠ)',          # æ€»ç»åŠ
            r'(ç®¡ç†å±‚)',          # ç®¡ç†å±‚
            r'(é«˜å±‚)',            # é«˜å±‚
        ]
        
        # è§’è‰²/èŒä½å…³é”®è¯æ¨¡å¼
        self.role_patterns = [
            r'(\w*ç»ç†)',         # ç»ç†
            r'(\w*ä¸»ç®¡)',         # ä¸»ç®¡
            r'(\w*è´Ÿè´£äºº)',       # è´Ÿè´£äºº
            r'(\w*ä¸“å‘˜)',         # ä¸“å‘˜
            r'(\w*å‘˜)',           # å‘˜å·¥
            r'(\w*å¸ˆ)',           # å·¥ç¨‹å¸ˆç­‰
            r'(\w*é•¿)',           # éƒ¨é•¿ã€ç§‘é•¿ç­‰
            r'(\w*æ€»)',           # æ€»ç›‘ã€æ€»ç»ç†ç­‰
            r'(\w*ä»£è¡¨)',         # ä»£è¡¨
            r'(å®¡æ ¸å‘˜)',          # å®¡æ ¸å‘˜
            r'(æ£€éªŒå‘˜)',          # æ£€éªŒå‘˜
            r'(æ“ä½œå‘˜)',          # æ“ä½œå‘˜
            r'(è´¨æ£€å‘˜)',          # è´¨æ£€å‘˜
            r'(é‡‡è´­å‘˜)',          # é‡‡è´­å‘˜
            r'(ä¸šåŠ¡å‘˜)',          # ä¸šåŠ¡å‘˜
            r'(æ–‡æ§å‘˜)',          # æ–‡æ§å‘˜
        ]
        
        # éœ€è¦æ’é™¤çš„é€šç”¨è¯æ±‡
        self.exclude_words = {
            'éƒ¨åˆ†', 'éƒ¨é—¨', 'å…¨éƒ¨', 'å†…éƒ¨', 'å¤–éƒ¨', 'å±€éƒ¨', 'å¤´éƒ¨', 'å°¾éƒ¨',
            'å®¤å†…', 'å®¤å¤–', 'æ•™å®¤', 'ä¼šè®®å®¤', 'åŠå…¬å®¤',
            'ç§‘å­¦', 'ç§‘æŠ€', 'å­¦ç§‘', 'æœ¬ç§‘',
            'ç»„ç»‡', 'ç»„æˆ', 'å°ç»„', 'å·¥ä½œç»„',
            'ä¸­å¿ƒæ€æƒ³', 'å¸‚ä¸­å¿ƒ', 'é‡å¿ƒ',
            'æ€»ç»“', 'æ€»è®¡', 'æ€»å’Œ', 'æ±‡æ€»',
            'é•¿åº¦', 'é•¿çŸ­', 'æˆé•¿', 'å¢é•¿',
            'å·¥ç¨‹å¸ˆ', 'ç¨‹åºå¸ˆ', 'è®¾è®¡å¸ˆ', 'åˆ†æå¸ˆ'
        }
        
        self.departments = Counter()
        self.roles = Counter()
        self.document_stats = []
        
    def read_document_content(self, file_path):
        """è¯»å–æ–‡æ¡£å†…å®¹"""
        try:
            if file_path.suffix.lower() == '.docx':
                # ç›´æ¥ä½¿ç”¨docxåº“è¯»å–
                from docx import Document
                doc = Document(file_path)
                
                # è¯»å–æ‰€æœ‰æ®µè½æ–‡æœ¬
                all_text = []
                for para in doc.paragraphs:
                    if para.text.strip():
                        all_text.append(para.text.strip())
                
                # è¯»å–è¡¨æ ¼å†…å®¹
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            if cell.text.strip():
                                all_text.append(cell.text.strip())
                
                return '\n'.join(all_text)
                
            elif file_path.suffix.lower() == '.doc':
                print(f"è·³è¿‡.docæ–‡ä»¶ï¼ˆä¸æ”¯æŒï¼‰: {file_path.name}")
                return ""
            elif file_path.suffix.lower() in ['.txt', '.md']:
                with open(file_path, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                print(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
                return ""
        except Exception as e:
            print(f"è¯»å–æ–‡æ¡£å¤±è´¥ {file_path}: {e}")
            return ""
    
    def extract_departments_and_roles(self, content, file_path):
        """ä»æ–‡æ¡£å†…å®¹ä¸­æå–éƒ¨é—¨å’Œè§’è‰²"""
        if not content:
            return [], []
        
        departments_found = set()
        roles_found = set()
        
        # æå–éƒ¨é—¨
        for pattern in self.department_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                if match and len(match) >= 2 and match not in self.exclude_words:
                    departments_found.add(match)
        
        # æå–è§’è‰²
        for pattern in self.role_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                if match and len(match) >= 2 and match not in self.exclude_words:
                    roles_found.add(match)
        
        return list(departments_found), list(roles_found)
    
    def analyze_document(self, file_path):
        """åˆ†æå•ä¸ªæ–‡æ¡£"""
        print(f"æ­£åœ¨åˆ†æ: {file_path.name}")
        
        content = self.read_document_content(file_path)
        departments, roles = self.extract_departments_and_roles(content, file_path)
        
        # æ›´æ–°è®¡æ•°å™¨
        for dept in departments:
            self.departments[dept] += 1
        for role in roles:
            self.roles[role] += 1
        
        # è®°å½•æ–‡æ¡£ç»Ÿè®¡ä¿¡æ¯
        doc_stat = {
            'file_name': file_path.name,
            'file_path': str(file_path),
            'departments_count': len(departments),
            'roles_count': len(roles),
            'departments': departments,
            'roles': roles,
            'content_length': len(content) if content else 0
        }
        self.document_stats.append(doc_stat)
        
        return departments, roles
    
    def analyze_all_documents(self):
        """åˆ†ææ‰€æœ‰æ–‡æ¡£"""
        # ä¼˜å…ˆä½¿ç”¨è½¬æ¢åçš„docxæ–‡ä»¶
        converted_dir = Path("S:/PG-GMO/01-Input/åŸå§‹æ–‡æ¡£/PG-ISOæ–‡ä»¶_docx")
        
        print(f"å¼€å§‹åˆ†æç›®å½•: {self.input_dir}")
        print(f"è½¬æ¢æ–‡æ¡£ç›®å½•: {converted_dir}")
        
        # æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶
        doc_files = []
        
        # ä¼˜å…ˆæŸ¥æ‰¾è½¬æ¢åçš„docxæ–‡ä»¶
        if converted_dir.exists():
            for root, dirs, files in os.walk(converted_dir):
                for file in files:
                    file_path = Path(root) / file
                    if file_path.suffix.lower() == '.docx':
                        doc_files.append(file_path)
            print(f"æ‰¾åˆ°è½¬æ¢åçš„docxæ–‡ä»¶: {len(doc_files)} ä¸ª")
        
        # å¦‚æœæ²¡æœ‰è½¬æ¢æ–‡ä»¶ï¼Œåˆ™ä½¿ç”¨åŸå§‹æ–‡æ¡£æ–‡ä»¶
        if not doc_files:
            for root, dirs, files in os.walk(self.input_dir):
                for file in files:
                    file_path = Path(root) / file
                    if file_path.suffix.lower() in ['.doc', '.docx', '.txt', '.md']:
                        doc_files.append(file_path)
            print(f"æ‰¾åˆ°åŸå§‹æ–‡æ¡£æ–‡ä»¶: {len(doc_files)} ä¸ª")
        
        if not doc_files:
            print("æœªæ‰¾åˆ°æ–‡æ¡£æ–‡ä»¶")
            print("å»ºè®®å…ˆè¿è¡Œdoc_to_docx_converter.pyè½¬æ¢.docæ–‡ä»¶")
            return self.generate_report()
        
        print(f"å¼€å§‹åˆ†æ {len(doc_files)} ä¸ªæ–‡æ¡£...")
        
        # åˆ†ææ¯ä¸ªæ–‡æ¡£
        for file_path in doc_files:
            try:
                self.analyze_document(file_path)
            except Exception as e:
                print(f"åˆ†ææ–‡æ¡£å¤±è´¥ {file_path}: {e}")
        
        return self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = {
            'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_documents': len(self.document_stats),
            'total_departments': len(self.departments),
            'total_roles': len(self.roles),
            'departments': dict(self.departments.most_common()),
            'roles': dict(self.roles.most_common()),
            'document_details': self.document_stats
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        json_file = self.output_dir / 'ISOæ–‡æ¡£éƒ¨é—¨è§’è‰²ç»Ÿè®¡æŠ¥å‘Š.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        md_file = self.output_dir / 'ISOæ–‡æ¡£éƒ¨é—¨è§’è‰²ç»Ÿè®¡æŠ¥å‘Š.md'
        self.generate_markdown_report(report, md_file)
        
        print(f"\nğŸ“Š åˆ†æå®Œæˆ!")
        print(f"ğŸ“ JSONæŠ¥å‘Š: {json_file}")
        print(f"ğŸ“„ MarkdownæŠ¥å‘Š: {md_file}")
        print(f"ğŸ“ˆ ç»Ÿè®¡ç»“æœ:")
        print(f"   - åˆ†ææ–‡æ¡£æ•°: {report['total_documents']}")
        print(f"   - å‘ç°éƒ¨é—¨æ•°: {report['total_departments']}")
        print(f"   - å‘ç°è§’è‰²æ•°: {report['total_roles']}")
        
        return report
    
    def generate_markdown_report(self, report, output_file):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# å“é«˜ISOæ–‡æ¡£éƒ¨é—¨è§’è‰²ç»Ÿè®¡åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {report['analysis_date']}\n")
            f.write(f"**åˆ†ææ–‡æ¡£æ•°**: {report['total_documents']}\n")
            f.write(f"**å‘ç°éƒ¨é—¨æ•°**: {report['total_departments']}\n")
            f.write(f"**å‘ç°è§’è‰²æ•°**: {report['total_roles']}\n\n")
            
            # éƒ¨é—¨ç»Ÿè®¡
            f.write("## ğŸ“Š éƒ¨é—¨ç»Ÿè®¡\n\n")
            f.write("| éƒ¨é—¨åç§° | å‡ºç°æ¬¡æ•° | å‡ºç°é¢‘ç‡ |\n")
            f.write("|----------|----------|----------|\n")
            total_dept_mentions = sum(report['departments'].values())
            for dept, count in report['departments'].items():
                frequency = f"{count/total_dept_mentions*100:.1f}%"
                f.write(f"| {dept} | {count} | {frequency} |\n")
            
            # è§’è‰²ç»Ÿè®¡
            f.write("\n## ğŸ‘¥ è§’è‰²ç»Ÿè®¡\n\n")
            f.write("| è§’è‰²åç§° | å‡ºç°æ¬¡æ•° | å‡ºç°é¢‘ç‡ |\n")
            f.write("|----------|----------|----------|\n")
            total_role_mentions = sum(report['roles'].values())
            for role, count in report['roles'].items():
                frequency = f"{count/total_role_mentions*100:.1f}%"
                f.write(f"| {role} | {count} | {frequency} |\n")
            
            # æ–‡æ¡£è¯¦æƒ…
            f.write("\n## ğŸ“‹ æ–‡æ¡£åˆ†æè¯¦æƒ…\n\n")
            f.write("| æ–‡æ¡£åç§° | éƒ¨é—¨æ•° | è§’è‰²æ•° | å†…å®¹é•¿åº¦ |\n")
            f.write("|----------|--------|--------|----------|\n")
            for doc in report['document_details']:
                f.write(f"| {doc['file_name']} | {doc['departments_count']} | {doc['roles_count']} | {doc['content_length']} |\n")
            
            # éƒ¨é—¨è¯¦ç»†åˆ†å¸ƒ
            f.write("\n## ğŸ¢ éƒ¨é—¨è¯¦ç»†åˆ†å¸ƒ\n\n")
            for doc in report['document_details']:
                if doc['departments']:
                    f.write(f"### {doc['file_name']}\n")
                    f.write("**éƒ¨é—¨**: " + ", ".join(doc['departments']) + "\n\n")
                    if doc['roles']:
                        f.write("**è§’è‰²**: " + ", ".join(doc['roles']) + "\n\n")
            
            f.write("\n---\n")
            f.write("*æŠ¥å‘Šç”±å“é«˜ISOæ–‡æ¡£éƒ¨é—¨è§’è‰²ç»Ÿè®¡åˆ†æå™¨è‡ªåŠ¨ç”Ÿæˆ*\n")

def main():
    # é…ç½®è·¯å¾„
    input_dir = "S:/PG-GMO/01-Input/åŸå§‹æ–‡æ¡£/PG-ISOæ–‡ä»¶"
    output_dir = "S:/PG-GMO/02-Output"
    
    # åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
    analyzer = DepartmentRoleAnalyzer(input_dir, output_dir)
    report = analyzer.analyze_all_documents()
    
    return report

if __name__ == "__main__":
    main()