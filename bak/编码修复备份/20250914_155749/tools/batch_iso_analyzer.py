#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ISOæ–‡æ¡£éƒ¨é—¨è§’è‰²åˆ†æå·¥å…·
ç”¨äºé‡æ–°åˆ†ææ‰€æœ‰ISOæ–‡æ¡£ï¼Œç¡®ä¿ç»Ÿè®¡çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§

ä½œè€…: é›¨ä¿Š
åˆ›å»ºæ—¶é—´: 2025-01-26
"""

import os
import json
import re
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from tools.office_document_reader import read_office_document
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥office_document_readerï¼Œå°†ä½¿ç”¨åŸºç¡€æ–‡æ¡£è¯»å–åŠŸèƒ½")
    
    def read_office_document(file_path):
        """åŸºç¡€æ–‡æ¡£è¯»å–åŠŸèƒ½"""
        try:
            if file_path.endswith('.docx'):
                from docx import Document
                doc = Document(file_path)
                content = []
                for paragraph in doc.paragraphs:
                    if paragraph.text.strip():
                        content.append(paragraph.text.strip())
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            if cell.text.strip():
                                content.append(cell.text.strip())
                return '\n'.join(content)
            else:
                return f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}"
        except Exception as e:
            return f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"

class BatchISOAnalyzer:
    """æ‰¹é‡ISOæ–‡æ¡£åˆ†æå™¨"""
    
    def __init__(self):
        self.base_path = Path("S:/PG-GMO/01-Input/åŸå§‹æ–‡æ¡£")
        self.output_path = Path("S:/PG-GMO/02-Output")
        
        # æ‰©å±•çš„éƒ¨é—¨å…³é”®è¯ï¼ˆåŸºäºHQ-QP-09çš„å‘ç°ï¼‰
        self.department_keywords = [
            'PMC', 'QC', 'QA', 'å¸‚åœºéƒ¨', 'å·¥ç¨‹éƒ¨', 'å“è´¨éƒ¨', 'è´§ä»“', 'äº”é‡‘éƒ¨', 
            'åˆ¶é€ éƒ¨', 'ç”Ÿäº§éƒ¨', 'ä»“åº“', 'è¡Œæ”¿éƒ¨', 'ä¸šåŠ¡éƒ¨', 'é‡‡è´­éƒ¨', 'è´¢åŠ¡éƒ¨',
            'æ€»ç»åŠ', 'è£…é…éƒ¨', 'ä¾›é”€ç§‘', 'æ£€éªŒç§‘', 'æ–‡æ§ä¸­å¿ƒ', 'è®¾è®¡éƒ¨',
            'è´¨å®‰éƒ¨', 'é¡¹ç›®éƒ¨', 'åŠå…¬å®¤', 'è¯•éªŒå®¤', 'è¾¨è¯†éƒ¨', 'æ£€æŸ¥ç»„',
            'å†…å®¡ç»„', 'å®¡æ ¸ç»„', 'å†…å®¡å°ç»„', 'å“è´¨éƒ¨æ–‡æ§ç»„', 'è½¦é—´ç»„', 'ç­ç»„',
            'é«˜å±‚', 'ç®¡ç†å±‚', 'å†…éƒ¨', 'å¤–éƒ¨', 'å†…å¤–éƒ¨'
        ]
        
        # æ‰©å±•çš„è§’è‰²å…³é”®è¯ï¼ˆåŸºäºHQ-QP-09çš„å‘ç°ï¼‰
        self.role_keywords = [
            'æ€»ç»ç†', 'å‰¯æ€»ç»ç†', 'ç»ç†', 'ä¸»ç®¡', 'è´Ÿè´£äºº', 'æŠ€å·¥', 'æ“ä½œå‘˜',
            'é¢†ç­', 'é‡‡è´­å‘˜', 'ç‰©æ–™å‘˜', 'åº“ç®¡', 'åˆ¶æ¨¡å·¥', 'æ£€éªŒå‘˜', 'è´¨æ£€å‘˜',
            'ä»“ç®¡å‘˜', 'ä»“åŠ¡å‘˜', 'è·Ÿå•å‘˜', 'ä¸“å‘˜', 'æ‹‰é•¿', 'ç”Ÿäº§çº¿æ‹‰é•¿',
            'è°ƒæœºå‘˜', 'å·¥æ¨¡å¸ˆ', 'ä¿®ç†å‘˜', 'ç”Ÿäº§å‘˜', 'ç»„é•¿', 'ç­ç»„é•¿',
            'è½¦é—´è´Ÿè´£äºº', 'è½¦é—´ç»„é•¿', 'ç®¡ç†è€…ä»£è¡¨', 'æŠ€æœ¯å‰¯æ€»', 'ä»˜æ€»',
            'å‰¯æ€»', 'äººå‘˜', 'å‘˜å·¥', 'å·¥ä½œäººå‘˜', 'æŠ€æœ¯äººå‘˜', 'ç®¡ç†äººå‘˜',
            'æ“ä½œäººå‘˜', 'æ£€æŸ¥å‘˜', 'è¯„ä»·å‘˜', 'è¯„å®¡å‘˜', 'æ–½å·¥äººå‘˜', 'è˜è¯·è€å¸ˆ'
        ]
        
        # ç»Ÿè®¡ç»“æœ
        self.department_stats = Counter()
        self.role_stats = Counter()
        self.document_results = {}
        self.total_documents = 0
        self.processed_documents = 0
        self.failed_documents = []
        
    def find_all_documents(self):
        """æŸ¥æ‰¾æ‰€æœ‰ISOæ–‡æ¡£"""
        documents = []
        
        # æŸ¥æ‰¾docxæ ¼å¼æ–‡æ¡£ï¼ˆä¼˜å…ˆï¼‰
        docx_path = self.base_path / "PG-ISOæ–‡ä»¶_docx"
        if docx_path.exists():
            for item in docx_path.rglob("*.docx"):
                if not item.name.startswith('~$'):  # æ’é™¤ä¸´æ—¶æ–‡ä»¶
                    documents.append(item)
        
        # æŸ¥æ‰¾docæ ¼å¼æ–‡æ¡£ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
        doc_path = self.base_path / "PG-ISOæ–‡ä»¶"
        if doc_path.exists():
            for item in doc_path.rglob("*.doc"):
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¯¹åº”çš„docxæ–‡ä»¶
                docx_equivalent = docx_path / item.relative_to(doc_path).with_suffix('.docx')
                if not docx_equivalent.exists():
                    documents.append(item)
        
        return sorted(documents)
    
    def analyze_document_content(self, content, doc_name):
        """åˆ†æå•ä¸ªæ–‡æ¡£å†…å®¹"""
        if not content or "è¯»å–æ–‡ä»¶å¤±è´¥" in content or "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼" in content:
            return {}, {}
        
        lines = content.split('\n')
        doc_departments = Counter()
        doc_roles = Counter()
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            if not line:
                continue
            
            # åˆ†æéƒ¨é—¨ - ä½¿ç”¨ç®€å•åŒ…å«åŒ¹é…ï¼ˆä¸ä¸“é—¨åˆ†æå·¥å…·ä¸€è‡´ï¼‰
            for dept in self.department_keywords:
                if dept in line:
                    # è®¡ç®—å‡ºç°æ¬¡æ•°
                    count = line.count(dept)
                    if count > 0:
                        doc_departments[dept] += count
                        print(f"  [{doc_name}] ç¬¬{line_num}è¡Œå‘ç°éƒ¨é—¨ '{dept}' {count}æ¬¡: {line[:100]}...")
            
            # åˆ†æè§’è‰² - ä½¿ç”¨ç®€å•åŒ…å«åŒ¹é…ï¼ˆä¸ä¸“é—¨åˆ†æå·¥å…·ä¸€è‡´ï¼‰
            for role in self.role_keywords:
                if role in line:
                    # è®¡ç®—å‡ºç°æ¬¡æ•°
                    count = line.count(role)
                    if count > 0:
                        doc_roles[role] += count
                        print(f"  [{doc_name}] ç¬¬{line_num}è¡Œå‘ç°è§’è‰² '{role}' {count}æ¬¡: {line[:100]}...")
        
        return doc_departments, doc_roles
    
    def analyze_single_document(self, doc_path):
        """åˆ†æå•ä¸ªæ–‡æ¡£"""
        doc_name = doc_path.name
        print(f"\næ­£åœ¨åˆ†æ: {doc_name}")
        print(f"æ–‡ä»¶è·¯å¾„: {doc_path}")
        
        try:
            # è¯»å–æ–‡æ¡£å†…å®¹
            content = read_office_document(str(doc_path))
            
            if not content or "è¯»å–æ–‡ä»¶å¤±è´¥" in content:
                print(f"  âŒ è¯»å–å¤±è´¥: {content}")
                self.failed_documents.append(str(doc_path))
                return
            
            print(f"  âœ… æˆåŠŸè¯»å–ï¼Œå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # åˆ†æå†…å®¹
            doc_departments, doc_roles = self.analyze_document_content(content, doc_name)
            
            # æ›´æ–°æ€»ç»Ÿè®¡
            self.department_stats.update(doc_departments)
            self.role_stats.update(doc_roles)
            
            # ä¿å­˜æ–‡æ¡£ç»“æœ
            self.document_results[doc_name] = {
                'path': str(doc_path),
                'departments': dict(doc_departments),
                'roles': dict(doc_roles),
                'content_length': len(content),
                'analysis_time': datetime.now().isoformat()
            }
            
            print(f"  ğŸ“Š å‘ç°éƒ¨é—¨: {len(doc_departments)} ä¸ª")
            print(f"  ğŸ‘¥ å‘ç°è§’è‰²: {len(doc_roles)} ä¸ª")
            
            self.processed_documents += 1
            
        except Exception as e:
            print(f"  âŒ åˆ†æå¤±è´¥: {str(e)}")
            self.failed_documents.append(str(doc_path))
    
    def run_analysis(self):
        """è¿è¡Œæ‰¹é‡åˆ†æ"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡ISOæ–‡æ¡£åˆ†æ...")
        print(f"åŸºç¡€è·¯å¾„: {self.base_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£
        documents = self.find_all_documents()
        self.total_documents = len(documents)
        
        print(f"\nğŸ“ æ‰¾åˆ° {self.total_documents} ä¸ªæ–‡æ¡£")
        
        if not documents:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£ï¼")
            return
        
        # åˆ†ææ¯ä¸ªæ–‡æ¡£
        for doc_path in documents:
            self.analyze_single_document(doc_path)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_reports()
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š æ€»æ–‡æ¡£æ•°: {self.total_documents}")
        print(f"âœ… æˆåŠŸå¤„ç†: {self.processed_documents}")
        print(f"âŒ å¤±è´¥æ–‡æ¡£: {len(self.failed_documents)}")
        
        if self.failed_documents:
            print("\nå¤±è´¥çš„æ–‡æ¡£:")
            for failed in self.failed_documents:
                print(f"  - {failed}")
    
    def generate_reports(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        json_report = {
            'analysis_info': {
                'timestamp': timestamp,
                'total_documents': self.total_documents,
                'processed_documents': self.processed_documents,
                'failed_documents': len(self.failed_documents),
                'analyzer_version': '2.0 - æ‰¹é‡é‡æ–°åˆ†æç‰ˆ'
            },
            'department_statistics': dict(self.department_stats.most_common()),
            'role_statistics': dict(self.role_stats.most_common()),
            'document_details': self.document_results,
            'failed_documents': self.failed_documents
        }
        
        json_file = self.output_path / "ISOæ–‡æ¡£æ‰¹é‡é‡æ–°åˆ†æç»“æœ.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ JSONæŠ¥å‘Šå·²ä¿å­˜: {json_file}")
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self.generate_markdown_report(timestamp)
    
    def generate_markdown_report(self, timestamp):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        md_content = f"""# ISOæ–‡æ¡£æ‰¹é‡é‡æ–°åˆ†ææŠ¥å‘Š ğŸ”„

**åˆ†ææ—¶é—´**: {timestamp}
**åˆ†æå·¥å…·**: æ‰¹é‡ISOåˆ†æå™¨ v2.0
**æ€»æ–‡æ¡£æ•°**: {self.total_documents}
**æˆåŠŸå¤„ç†**: {self.processed_documents}
**å¤±è´¥æ–‡æ¡£**: {len(self.failed_documents)}

## ğŸ”¥ é‡è¦è¯´æ˜

æœ¬æ¬¡åˆ†ææ˜¯å¯¹ä¹‹å‰ç»Ÿè®¡ç»“æœçš„å…¨é¢é‡æ–°æ£€æŸ¥ï¼Œä½¿ç”¨æ”¹è¿›çš„åˆ†æå·¥å…·ç¡®ä¿å‡†ç¡®æ€§ã€‚
åŸºäºæ¨è€å¸ˆå‘ç°çš„HQ-QP-09ç»Ÿè®¡é—æ¼é—®é¢˜ï¼Œå¯¹æ‰€æœ‰æ–‡æ¡£è¿›è¡Œäº†é‡æ–°åˆ†æã€‚

## ğŸ“Š éƒ¨é—¨ç»Ÿè®¡æ€»è§ˆ

| æ’å | éƒ¨é—¨åç§° | å‡ºç°æ¬¡æ•° | å æ¯” |
|------|----------|----------|------|
"""
        
        total_dept_count = sum(self.department_stats.values())
        for i, (dept, count) in enumerate(self.department_stats.most_common(20), 1):
            percentage = (count / total_dept_count * 100) if total_dept_count > 0 else 0
            md_content += f"| {i} | **{dept}** | {count} | {percentage:.1f}% |\n"
        
        md_content += f"\n**éƒ¨é—¨æ€»è®¡**: {len(self.department_stats)} ä¸ªä¸åŒéƒ¨é—¨\n"
        md_content += f"**éƒ¨é—¨æåŠæ€»æ¬¡æ•°**: {total_dept_count} æ¬¡\n\n"
        
        md_content += "## ğŸ‘¥ è§’è‰²ç»Ÿè®¡æ€»è§ˆ\n\n"
        md_content += "| æ’å | è§’è‰²åç§° | å‡ºç°æ¬¡æ•° | å æ¯” |\n"
        md_content += "|------|----------|----------|------|\n"
        
        total_role_count = sum(self.role_stats.values())
        for i, (role, count) in enumerate(self.role_stats.most_common(20), 1):
            percentage = (count / total_role_count * 100) if total_role_count > 0 else 0
            md_content += f"| {i} | **{role}** | {count} | {percentage:.1f}% |\n"
        
        md_content += f"\n**è§’è‰²æ€»è®¡**: {len(self.role_stats)} ä¸ªä¸åŒè§’è‰²\n"
        md_content += f"**è§’è‰²æåŠæ€»æ¬¡æ•°**: {total_role_count} æ¬¡\n\n"
        
        # æ·»åŠ æ–‡æ¡£è¯¦æƒ…
        md_content += "## ğŸ“‹ æ–‡æ¡£åˆ†æè¯¦æƒ…\n\n"
        
        for doc_name, details in sorted(self.document_results.items()):
            md_content += f"### {doc_name}\n\n"
            
            if details['departments']:
                md_content += "**éƒ¨é—¨**: "
                dept_list = [f"{dept}({count}æ¬¡)" for dept, count in sorted(details['departments'].items(), key=lambda x: x[1], reverse=True)]
                md_content += ", ".join(dept_list) + "\n\n"
            else:
                md_content += "**éƒ¨é—¨**: æœªå‘ç°\n\n"
            
            if details['roles']:
                md_content += "**è§’è‰²**: "
                role_list = [f"{role}({count}æ¬¡)" for role, count in sorted(details['roles'].items(), key=lambda x: x[1], reverse=True)]
                md_content += ", ".join(role_list) + "\n\n"
            else:
                md_content += "**è§’è‰²**: æœªå‘ç°\n\n"
        
        if self.failed_documents:
            md_content += "## âŒ å¤„ç†å¤±è´¥çš„æ–‡æ¡£\n\n"
            for failed in self.failed_documents:
                md_content += f"- {failed}\n"
            md_content += "\n"
        
        md_content += f"## ğŸ“ˆ åˆ†ææ€»ç»“\n\n"
        md_content += f"- æœ¬æ¬¡é‡æ–°åˆ†æå‘ç°äº† **{len(self.department_stats)}** ä¸ªä¸åŒéƒ¨é—¨\n"
        md_content += f"- æœ¬æ¬¡é‡æ–°åˆ†æå‘ç°äº† **{len(self.role_stats)}** ä¸ªä¸åŒè§’è‰²\n"
        md_content += f"- éƒ¨é—¨æåŠæ€»æ¬¡æ•°: **{total_dept_count}** æ¬¡\n"
        md_content += f"- è§’è‰²æåŠæ€»æ¬¡æ•°: **{total_role_count}** æ¬¡\n"
        md_content += f"- æˆåŠŸå¤„ç†æ–‡æ¡£: **{self.processed_documents}/{self.total_documents}** ä¸ª\n\n"
        
        md_content += "---\n\n"
        md_content += "*æœ¬æŠ¥å‘Šç”±æ‰¹é‡ISOåˆ†æå™¨è‡ªåŠ¨ç”Ÿæˆ*\n"
        
        md_file = self.output_path / "ISOæ–‡æ¡£æ‰¹é‡é‡æ–°åˆ†ææŠ¥å‘Š.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"ğŸ“„ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {md_file}")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = BatchISOAnalyzer()
    analyzer.run_analysis()

if __name__ == "__main__":
    main()